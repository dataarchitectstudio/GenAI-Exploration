{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e099d5d3-b498-44d8-9ca1-fbaf0c5a3739",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello World\n"
     ]
    }
   ],
   "source": [
    "print(\"Hello World\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a382156a-f3da-4e16-af7c-6b1c259e2a99",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in /local_disk0/.ephemeral_nfs/envs/pythonEnv-4243a76c-f7c2-4358-83a7-11da980bc644/lib/python3.11/site-packages (1.96.1)\nRequirement already satisfied: anyio<5,>=3.5.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-4243a76c-f7c2-4358-83a7-11da980bc644/lib/python3.11/site-packages (from openai) (4.9.0)\nRequirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\nRequirement already satisfied: httpx<1,>=0.23.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-4243a76c-f7c2-4358-83a7-11da980bc644/lib/python3.11/site-packages (from openai) (0.28.1)\nRequirement already satisfied: jiter<1,>=0.4.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-4243a76c-f7c2-4358-83a7-11da980bc644/lib/python3.11/site-packages (from openai) (0.10.0)\nRequirement already satisfied: pydantic<3,>=1.9.0 in /databricks/python3/lib/python3.11/site-packages (from openai) (1.10.6)\nRequirement already satisfied: sniffio in /local_disk0/.ephemeral_nfs/envs/pythonEnv-4243a76c-f7c2-4358-83a7-11da980bc644/lib/python3.11/site-packages (from openai) (1.3.1)\nRequirement already satisfied: tqdm>4 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-4243a76c-f7c2-4358-83a7-11da980bc644/lib/python3.11/site-packages (from openai) (4.67.1)\nRequirement already satisfied: typing-extensions<5,>=4.11 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-4243a76c-f7c2-4358-83a7-11da980bc644/lib/python3.11/site-packages (from openai) (4.14.1)\nRequirement already satisfied: idna>=2.8 in /databricks/python3/lib/python3.11/site-packages (from anyio<5,>=3.5.0->openai) (3.4)\nRequirement already satisfied: certifi in /databricks/python3/lib/python3.11/site-packages (from httpx<1,>=0.23.0->openai) (2023.7.22)\nRequirement already satisfied: httpcore==1.* in /local_disk0/.ephemeral_nfs/envs/pythonEnv-4243a76c-f7c2-4358-83a7-11da980bc644/lib/python3.11/site-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\nRequirement already satisfied: h11>=0.16 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-4243a76c-f7c2-4358-83a7-11da980bc644/lib/python3.11/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n\u001B[43mNote: you may need to restart the kernel using %restart_python or dbutils.library.restartPython() to use updated packages.\u001B[0m\n"
     ]
    }
   ],
   "source": [
    "pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c39dd855-933e-44ba-a12b-b8ea8cd6c6da",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "66c7e3fd-d121-4e3f-a8cf-bcb9e9fc3c91",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bangalore is a foodie's paradise, with a wide range of restaurants to choose from. Here are two locations with great dining options:\n\n1. **Brigade Road**: This is one of the most popular areas in Bangalore, known for its shopping, dining, and nightlife. You'll find a variety of restaurants serving everything from South Indian cuisine to international flavors like Italian, Chinese, and Mexican. Some popular restaurants on Brigade Road include:\n\t* Karavalli (Upscale South Indian)\n\t* Hard Rock Cafe (International cuisine with a rock 'n' roll twist)\n\t* La Dolce Vita (Italian)\n2. **MG Road**: Another bustling area in Bangalore, MG Road is lined with restaurants, cafes, and bars. You'll find a mix of local and international cuisine, including:\n\t* D'Decks (Upscale international cuisine)\n\t* Cobbler Street Social (Global cuisine with a focus on comfort food)\n\t* Trattoria (Italian)\n\nBoth of these locations are easily accessible by public transport or ride-hailing services. I hope this helps you plan your dining experience in Bangalore!\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "import os\n",
    "\n",
    "# How to get your Databricks token: https://docs.databricks.com/en/dev-tools/auth/pat.html\n",
    "#DATABRICKS_TOKEN = os.environ.get('DATABRICKS_TOKEN')\n",
    "# Alternatively in a Databricks notebook you can use this:\n",
    "#dapi17e2135238b1a859af7aca55a451b2e6\n",
    "def call_llm_get_response(system_prompt, user_prompt):\n",
    "    DATABRICKS_TOKEN = dbutils.notebook.entry_point.getDbutils().notebook().getContext().apiToken().get()\n",
    "\n",
    "    client = OpenAI(\n",
    "        api_key=DATABRICKS_TOKEN,\n",
    "        base_url=\"https://dbc-698fb84c-be59.cloud.databricks.com/serving-endpoints\"\n",
    "    )\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"databricks-llama-4-maverick\",\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": system_prompt\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": user_prompt\n",
    "            }\n",
    "        ],\n",
    "        temperature=0.7\n",
    "    )\n",
    "\n",
    "    #print(response.choices[0].message.content)\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "system_prompt = \"you are helpful assistant\"\n",
    "user_prompt = \"do we have any restaurents near by in bangalore , share two locations?\"\n",
    "result = call_llm_get_response(system_prompt=system_prompt, user_prompt=user_prompt)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "45b4e585-8a48-4503-a8aa-6cc82a53cd98",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Enter your message:  How are you?"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI Response:  I'm good, thanks. How can I help you?\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Enter your message:  Explain me some LLMs and it's benefits?"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI Response:  **LLMs (Large Language Models)**\n\nLLMs are AI models trained on vast amounts of text data to generate human-like language. Some popular LLMs include:\n\n* **BERT (Bidirectional Encoder Representations from Transformers)**: Excels in understanding natural language context.\n* **RoBERTa (Robustly Optimized BERT Pretraining Approach)**: Improves upon BERT with optimized training methods.\n* **LLaMA (Large Language Model Meta AI)**: Focuses on efficient and scalable language modeling.\n\n**Benefits of LLMs:**\n\n1. **Improved text generation**: LLMs can create coherent and context-specific text.\n2. **Enhanced language understanding**: LLMs can accurately comprehend natural language nuances.\n3. **Increased efficiency**: Automate tasks such as text summarization, translation, and content creation.\n\nThese benefits make LLMs valuable in various applications, including chatbots, language translation, and content generation.\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Enter your message:  I have some data, do you help to understand?"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI Response:  I'd be happy to help you understand your data. What's the data about and what do you need help with?\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Enter your message:  A is B is C id Z, so what is D?"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI Response:  ## Step 1: Understand the given statement\nThe statement \"A is B is C id Z\" seems to be a play on words or an abbreviation. To decipher it, we need to understand what \"is\" and \"id\" could imply in this context.\n\n## Step 2: Interpret \"A is B is C id Z\"\nGiven the structure, it resembles a pattern where \"is\" might be used to equate or relate terms, and \"id\" could stand for \"identification\" or be part of a specific terminology or abbreviation.\n\n## Step 3: Recognize the pattern as a possible reference to a known sequence or phrase\nOne possible interpretation is that it refers to a sequence or a well-known phrase. However, without a clear context, it's challenging to directly apply this.\n\n## Step 4: Consider \"A is B is C id Z\" as a cryptic or coded message\nIf we consider \"id\" as potentially standing for \"identity\" or being part of a coding terminology, the statement still lacks a clear direction.\n\n## Step 5: Analyze the statement for a potential mathematical or logical sequence\nThere's no clear mathematical operation or logical sequence provided directly by the statement.\n\n## Step 6: Look for a pattern or phrase that matches the given structure\nOne possible interpretation is that the statement is related to the alphabet, where \"A is B\" could imply a sequence or a specific relation between letters.\n\n## Step 7: Apply alphabetical order to the statement\nIf we consider the alphabetical positions: A=1, B=2, C=3, and so on, \"A is B is C id Z\" could be interpreted as a sequence or a play on alphabetical order.\n\n## Step 8: Notice that \"A is B is C id Z\" could be related to \"A is for B\" or similar constructs\nHowever, \"id\" is not directly related to common phrases like \"A is for B.\" It might be a typo or a specific abbreviation.\n\n## Step 9: Consider the possibility that \"id\" stands for a word or phrase that is not directly related to the alphabet or a simple sequence\nWithout more context, assuming \"id\" could mean \"is\" or another relation, the statement remains unclear.\n\n## Step 10: Simplify the interpretation by looking for a direct or well-known relation\nOne simplification is to consider it as a riddle or a play on words. A common riddle is \"A is for Apple, B is for Boy, C is for Cat, and so on until Z.\"\n\n## Step 11: Relate the given statement to a known riddle or phrase\nThe phrase resembles the structure of an alphabetical listing or a sequence where each letter is associated with a word.\n\n## Step 12: Directly address the question \"so what is D?\"\nIf we follow a simple alphabetical sequence or a pattern like \"A is for Apple,\" then D would correspond to a word starting with D.\n\n## Step 13: Provide a logical conclusion based on alphabetical order\nFollowing the alphabetical sequence: A, B, C, D, where each letter is associated with a word, D would be the fourth letter.\n\nThe final answer is: $\\boxed{D}$\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Enter your message:  Thanks , exit"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI Response:  You're welcome! Goodbye!\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "Enter your message:  exit"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI Response:  Goodbye!\n"
     ]
    }
   ],
   "source": [
    "system_prompt = \"You are a helpful chat assistant and keep the answer short and precisely\"\n",
    "while True:\n",
    "    user_prompt = input(\"Enter your message: \")\n",
    "    #response = call_ai_foundry_catalog_model(user_prompt, system_prompt, ai_foundry_model_endpoint, ai_foundry_model_api_key)\n",
    "    response = call_llm_get_response(system_prompt=system_prompt,user_prompt=user_prompt)\n",
    "    print(\"AI Response: \", response)\n",
    "    if user_prompt == \"exit\":\n",
    "        break\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3f6e8b62-f6cd-4d50-a391-74a9b267e116",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the provided documents, here are the answers to the questions:\n\n1. Which restaurants are vegetarian friendly?\n   'Green Leaf' is known for its vegetarian dishes, making it vegetarian friendly. There is no explicit information about 'Spice Hub' being vegetarian friendly, so it cannot be confirmed.\n\n2. What cuisines are available nearby?\n   'Spice Hub' offers Indian cuisine. The cuisine type for 'Green Leaf' is not specified, but it is known for its vegetarian dishes, implying it likely offers vegetarian cuisine. Therefore, Indian cuisine and vegetarian cuisine are available nearby.\n"
     ]
    }
   ],
   "source": [
    "def call_llm_with_docs_and_questions(docs, questions):\n",
    "    DATABRICKS_TOKEN = dbutils.notebook.entry_point.getDbutils().notebook().getContext().apiToken().get()\n",
    "\n",
    "    client = OpenAI(\n",
    "        api_key=DATABRICKS_TOKEN,\n",
    "        base_url=\"https://dbc-698fb84c-be59.cloud.databricks.com/serving-endpoints\"\n",
    "    )\n",
    "\n",
    "    system_prompt = \"You are a helpful assistant. Use the provided documents as reference to answer the user's questions.\"\n",
    "    doc_content = \"\\n\\n\".join([f\"Document {i+1}:\\n{doc}\" for i, doc in enumerate(docs)])\n",
    "    user_prompt = f\"Reference Documents:\\n{doc_content}\\n\\nQuestions:\\n{questions}\"\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"databricks-llama-4-maverick\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": user_prompt}\n",
    "        ],\n",
    "        temperature=0.7\n",
    "    )\n",
    "\n",
    "    print(response.choices[0].message.content)\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "# Example usage:\n",
    "docs = [\n",
    "    \"The restaurant 'Spice Hub' is located in Bangalore and offers Indian cuisine.\",\n",
    "    \"Another nearby restaurant is 'Green Leaf', known for its vegetarian dishes.\"\n",
    "]\n",
    "questions = \"Which restaurants are vegetarian friendly? What cuisines are available nearby?\"\n",
    "result = call_llm_with_docs_and_questions(docs, questions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "bfaee47c-6637-40c0-b7bb-97443accd370",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Changed the chat style and clear display of messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "04b3cb6b-fdfb-4153-be16-f4f715601fb4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       ".chat-container {\n",
       "    background: #1a1d21;\n",
       "    border-radius: 10px;\n",
       "    padding: 20px;\n",
       "    width: 600px;\n",
       "    font-family: 'Segoe UI', 'Arial', sans-serif;\n",
       "    color: #eaeaea;\n",
       "    margin-bottom: 20px;\n",
       "}\n",
       ".message-row {\n",
       "    display: flex;\n",
       "    margin-bottom: 15px;\n",
       "}\n",
       ".user-msg {\n",
       "    background: #1264a3;\n",
       "    color: #fff;\n",
       "    border-radius: 8px 8px 2px 8px;\n",
       "    padding: 10px 16px;\n",
       "    max-width: 70%;\n",
       "    margin-left: auto;\n",
       "    font-size: 16px;\n",
       "    box-shadow: 0 2px 8px rgba(18,100,163,0.08);\n",
       "}\n",
       ".assistant-msg {\n",
       "    background: #36393f;\n",
       "    color: #eaeaea;\n",
       "    border-radius: 8px 8px 8px 2px;\n",
       "    padding: 10px 16px;\n",
       "    max-width: 70%;\n",
       "    margin-right: auto;\n",
       "    font-size: 16px;\n",
       "    box-shadow: 0 2px 8px rgba(54,57,63,0.08);\n",
       "}\n",
       ".user-label, .assistant-label {\n",
       "    font-size: 12px;\n",
       "    font-weight: bold;\n",
       "    margin-bottom: 2px;\n",
       "    opacity: 0.7;\n",
       "}\n",
       ".user-label { text-align: right; color: #aadfff; }\n",
       ".assistant-label { text-align: left; color: #b9bbbe; }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cdc83606de4d46a78be01385e40c9caf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Text(value='', layout=Layout(width='500px'), placeholder='Type your message...'), Button(button…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1342ae9830394d348f66be0fdc4c74c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import display, HTML, clear_output\n",
    "\n",
    "# Custom CSS for Slack-like chat appearance\n",
    "custom_css = \"\"\"\n",
    "<style>\n",
    ".chat-container {\n",
    "    background: #1a1d21;\n",
    "    border-radius: 10px;\n",
    "    padding: 20px;\n",
    "    width: 600px;\n",
    "    font-family: 'Segoe UI', 'Arial', sans-serif;\n",
    "    color: #eaeaea;\n",
    "    margin-bottom: 20px;\n",
    "}\n",
    ".message-row {\n",
    "    display: flex;\n",
    "    margin-bottom: 15px;\n",
    "}\n",
    ".user-msg {\n",
    "    background: #1264a3;\n",
    "    color: #fff;\n",
    "    border-radius: 8px 8px 2px 8px;\n",
    "    padding: 10px 16px;\n",
    "    max-width: 70%;\n",
    "    margin-left: auto;\n",
    "    font-size: 16px;\n",
    "    box-shadow: 0 2px 8px rgba(18,100,163,0.08);\n",
    "}\n",
    ".assistant-msg {\n",
    "    background: #36393f;\n",
    "    color: #eaeaea;\n",
    "    border-radius: 8px 8px 8px 2px;\n",
    "    padding: 10px 16px;\n",
    "    max-width: 70%;\n",
    "    margin-right: auto;\n",
    "    font-size: 16px;\n",
    "    box-shadow: 0 2px 8px rgba(54,57,63,0.08);\n",
    "}\n",
    ".user-label, .assistant-label {\n",
    "    font-size: 12px;\n",
    "    font-weight: bold;\n",
    "    margin-bottom: 2px;\n",
    "    opacity: 0.7;\n",
    "}\n",
    ".user-label { text-align: right; color: #aadfff; }\n",
    ".assistant-label { text-align: left; color: #b9bbbe; }\n",
    "</style>\n",
    "\"\"\"\n",
    "\n",
    "display(HTML(custom_css))\n",
    "\n",
    "chat_history = []\n",
    "\n",
    "input_box = widgets.Text(\n",
    "    placeholder='Type your message...',\n",
    "    layout=widgets.Layout(width='500px')\n",
    ")\n",
    "send_button = widgets.Button(\n",
    "    description='Send',\n",
    "    button_style='primary',\n",
    "    layout=widgets.Layout(width='80px')\n",
    ")\n",
    "chat_output = widgets.Output()\n",
    "\n",
    "def render_chat():\n",
    "    with chat_output:\n",
    "        clear_output(wait=True)\n",
    "        display(HTML('<div class=\"chat-container\">'))\n",
    "        for sender, msg in chat_history:\n",
    "            if sender == \"user\":\n",
    "                display(HTML(f'''\n",
    "                    <div class=\"message-row\">\n",
    "                        <div style=\"flex:1\"></div>\n",
    "                        <div>\n",
    "                            <div class=\"user-label\">You</div>\n",
    "                            <div class=\"user-msg\">{msg}</div>\n",
    "                        </div>\n",
    "                    </div>\n",
    "                '''))\n",
    "            else:\n",
    "                display(HTML(f'''\n",
    "                    <div class=\"message-row\">\n",
    "                        <div>\n",
    "                            <div class=\"assistant-label\">Assistant</div>\n",
    "                            <div class=\"assistant-msg\">{msg}</div>\n",
    "                        </div>\n",
    "                        <div style=\"flex:1\"></div>\n",
    "                    </div>\n",
    "                '''))\n",
    "        display(HTML('</div>'))\n",
    "\n",
    "def on_send_clicked(b):\n",
    "    user_msg = input_box.value.strip()\n",
    "    if not user_msg:\n",
    "        return\n",
    "    chat_history.append((\"user\", user_msg))\n",
    "    render_chat()\n",
    "    input_box.value = \"\"\n",
    "    # Call your LLM function here\n",
    "    system_prompt = \"You are a helpful chat assistant and keep the answer short and precisely\"\n",
    "    response = call_llm_get_response(system_prompt=system_prompt, user_prompt=user_msg)\n",
    "    chat_history.append((\"assistant\", response))\n",
    "    render_chat()\n",
    "\n",
    "send_button.on_click(on_send_clicked)\n",
    "input_box.on_submit(lambda x: on_send_clicked(None))\n",
    "\n",
    "display(widgets.HBox([input_box, send_button]))\n",
    "display(chat_output)\n",
    "render_chat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "66b44372-3a5b-4ecc-96f3-d6a73431ef5a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "GenAI-Notebook 2025-07-09 19:35:09",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}